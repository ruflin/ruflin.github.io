<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Ruflin.com]]></title>
  <link href="http://ruflin.com/atom.xml" rel="self"/>
  <link href="http://ruflin.com/"/>
  <updated>2013-05-19T14:48:04+02:00</updated>
  <id>http://ruflin.com/</id>
  <author>
    <name><![CDATA[Nicolas Ruflin]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Include Elastica in your project as svn:externals]]></title>
    <link href="http://ruflin.com/2011/12/21/include-elastica-in-your-project-as-svn-externals/"/>
    <updated>2011-12-21T10:57:00+01:00</updated>
    <id>http://ruflin.com/2011/12/21/include-elastica-in-your-project-as-svn-externals</id>
    <content type="html"><![CDATA[<p>As most of you know, <a href="https://github.com/ruflin/Elastica">Elastica</a> is hosted on <a href="https://github.com/">github</a>, which means it uses <a href="http://git-scm.com/">git</a> as its <a href="http://en.wikipedia.org/wiki/Version_control">revision control</a> system. I have several projects which include Elastica but use <a href="http://subversion.tigris.org/">subversion</a> as its version control system. Until now, I included Elastica as an external svn source by hosting my own Elastica svn repository. But yesterday I discovered that the code from github can also be checked out through svn. I immediately asked google to get more details about this feature and discovered several blog entries on the <a href="https://github.com/blog/966-improved-subversion-client-support">github blog</a> which I had somehow missed.</p>




<p>It is not only possible to check out repositories, but also to check out some specific subfolders or tags and you can even commit to the repository (which I didn&#8217;t test). As in my projects I only use the Elastica library folder and don&#8217;t need all the tests and additional data, I check out only the lib folder. If you want to check out the Elastica lib folder from version v0.18.6.0, use the following line of code:</p>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>svn co https://github.com/ruflin/Elastica/tags/v0.18.6.0/lib/ .</span></code></pre></td></tr></table></div></figure>




<p>If you have a lib folder in your project with all your frameworks and libraries and you want to add Elastica as an external source (which is quite useful), you can set the <a href="http://svnbook.red-bean.com/en/1.0/ch07s03.html">svn:externals property</a> on your library folder to the following.</p>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>https://github.com/ruflin/Elastica/tags/v0.18.6.0/lib/Elastica Elastica</span></code></pre></td></tr></table></div></figure>




<p>If you already have other sources added as externals to your repository (for example ZF), just add this line below your existing lines. The next time you will update your repository, the Elastica folder with all its files will be checked out. To update to one of the next versions of Elastica, update the version number in the url in your svn:externals properties.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Elastica with multiple Elasticsearch Nodes]]></title>
    <link href="http://ruflin.com/2011/11/21/using-elastica-with-multiple-elasticsearch-nodes/"/>
    <updated>2011-11-21T13:05:00+01:00</updated>
    <id>http://ruflin.com/2011/11/21/using-elastica-with-multiple-elasticsearch-nodes</id>
    <content type="html"><![CDATA[<p>Elasticsearch was built with the cloud / multiple distributed servers in mind. It is quite easy to start a <a href="http://www.elasticsearch.org/guide/reference/modules/cluster.html">elasticsearch cluster</a> simply by starting multiple instances of elasticsearch on one server or on multiple servers. Every elasticsearch instance is called <a href="http://www.elasticsearch.org/guide/reference/api/admin-cluster-nodes-info.html">a node</a>. To start multiple instances of elasticsearch on your local machine, just run the following command in the elasticsearch folder twice:</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>./bin/elasticsearch -f
</span><span class='line'>./bin/elasticsearch -f
</span></code></pre></td></tr></table></div></figure>




<p>As you will see, the first node will be started on port 9200, the second instance on port 9201. Elasticsearch automatically discovers the other node and creates a cluster. Elastica can be used to retrieve all node and cluster information. In the following example first the cluster object is retrieved (Elastica_Cluster) from the client and then the <a href="http://www.elasticsearch.org/guide/reference/api/admin-cluster-state.html">cluster state</a> is read out. Then all cluster nodes (Elastica_Node) are retrieved and the name of every node is printed out. Every cluster has at least one node and every node has a specific name.</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="x">$client = new Elastica_Client();</span>
</span><span class='line'>
</span><span class='line'><span class="x">// Retrieve a Elastica_Cluster object</span>
</span><span class='line'><span class="x">$cluster = $client-&gt;getCluster();</span>
</span><span class='line'>
</span><span class='line'><span class="x">// Returns the cluster state</span>
</span><span class='line'><span class="x">$state = $cluster-&gt;getState();</span>
</span><span class='line'>
</span><span class='line'><span class="x">// Gets all cluster notes</span>
</span><span class='line'><span class="x">$nodes = $cluster-&gt;getNodes();</span>
</span><span class='line'>
</span><span class='line'><span class="x">foreach ($nodes as $node) {</span>
</span><span class='line'><span class="x">    echo $node-&gt;getName();</span>
</span><span class='line'><span class="x">}</span>
</span></code></pre></td></tr></table></div></figure>




<h2>Client to multiple servers</h2>




<p>As elasticsearch is a distributed search engine that can be run on multiple servers, it is possible that some servers fail and still, the search works as expected as the data is stored redundantly (replicas). The <a href="http://www.elasticsearch.org/guide/reference/api/admin-indices-create-index.html">number of shards and replicas</a> can be chosen for every single index during creation. Of course, this can also be set with Elastica through the mapping as can be seen in the <a href="https://github.com/ruflin/Elastica/blob/master/test/lib/Elastica/IndexTest.php">Elastica_Index test</a>. More details on this perhaps in a later blog post.</p>




<p>One of the goals of the distributed search index is availability. If one server goes down, search results should still be served. But if the client connects to only the server that just went down, no results are returned anymore. Because of this, Elastica_Client supports multiple servers which are accessed in a round robin algorithm. This is the only and also most basic option at the moment. So if we start a node on port 9200 and port 9201 above, we pass the following arguments to Elastica_Client to access both servers.</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="x">$client = new Elastica_Client(array(</span>
</span><span class='line'><span class="x">  &#39;servers&#39; =&gt; array(</span>
</span><span class='line'><span class="x">      array(&#39;host&#39; =&gt; &#39;localhost&#39;, &#39;port&#39; =&gt; 9200)</span>
</span><span class='line'><span class="x">      array(&#39;host&#39; =&gt; &#39;localhost&#39;, &#39;port&#39; =&gt; 9201)</span>
</span><span class='line'><span class="x">  )</span>
</span><span class='line'><span class="x">));</span>
</span></code></pre></td></tr></table></div></figure>




<p>From now on, every request is sent to one of these servers in a round robin type. Instead of localhost, an external server could be used in addition. I&#8217;m aware that this is still a quite basic implementation. As probably some of you already realized, this is no safe failover method, as every second request still goes onto the server that is down. One idea here is to give a specific threshold for every server in which the respond time should be and otherwise the query goes to the next server. In addition, it would be useful to store this information on unavailable servers somewhere in order to use it for the next request. Thus, only one client has to wait for the unavailable server. Storing this information is somehow an issue, since Elastica does not have any storage backend.</p>




<h2>Load Distribution</h2>




<p>This client implementation also allows to distribute the load on multiple nodes. As far as I know, Elasticsearch already does this quite well on its own. But it helps if more than one node can answer http requests. Therefore, the method above is really useful if you use more than one elasticsearch node in a cluster to send your request to all servers.</p>




<p>It is planned to enhance this multiple server implementation in the future with additional parameters such as priority for a server and some other ideas. Please feel free to write down your ideas in the comment section or directly create a pull request on github.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Log Requests in Elastica]]></title>
    <link href="http://ruflin.com/2011/11/20/how-to-log-requests-in-elastica/"/>
    <updated>2011-11-20T13:46:00+01:00</updated>
    <id>http://ruflin.com/2011/11/20/how-to-log-requests-in-elastica</id>
    <content type="html"><![CDATA[<p>In the <a href="https://github.com/ruflin/Elastica/tree/v0.18.4.1" target="_blank">Elastica Release v0.18.4.1</a>, the capability to log requests was added. There is a general Elastica_Log object that can later also be extended to log other things such as responses, exceptions and more. The Elastica_Log constructor takes an Elastica_Client as param. To enable logging, the config variable log for the client has to be set to true, or a specific path the log should be written to. This means that every client instance decides on its own whether logging is enabled or not.</p>




<p>The example below will log the message &#8220;hello world&#8221; to the general PHP log.</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="nv">$client</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Elastica_Client</span><span class="p">(</span><span class="k">array</span><span class="p">(</span><span class="s1">&#39;log&#39;</span> <span class="o">=&gt;</span> <span class="k">true</span><span class="p">));</span>
</span><span class='line'><span class="nv">$log</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Elastica_Log</span><span class="p">(</span><span class="nv">$client</span><span class="p">);</span>
</span><span class='line'><span class="nv">$log</span><span class="o">-&gt;</span><span class="na">log</span><span class="p">(</span><span class="s1">&#39;hello world&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>




<br />




<p>If a file path is set as the log config param, the error log will write the &#8220;hello world&#8221; message to the /tmp/php.log file.</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="nv">$client</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Elastica_Client</span><span class="p">(</span><span class="k">array</span><span class="p">(</span><span class="s1">&#39;log&#39;</span> <span class="o">=&gt;</span> <span class="s1">&#39;/tmp/php.log&#39;</span><span class="p">));</span>
</span><span class='line'><span class="nv">$log</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Elastica_Log</span><span class="p">(</span><span class="nv">$client</span><span class="p">);</span>
</span><span class='line'><span class="nv">$log</span><span class="o">-&gt;</span><span class="na">log</span><span class="p">(</span><span class="s1">&#39;hello world&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>




<br />




<p>If logging is enabled, all request are at the moment automatically logged. There is a special conversion of request to log messages. The log message is converted to the shell format, so every log line can directly be pasted into the shell to test out. This is quite nice to debug and to create a gist if others ask what the query looks like. Furthermore, this makes it simpler to figure out whether the problem relates to Elastica or not.</p>




<p>For example the output for updating the number of replicas setting request for the index test would look like below.</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">curl -XPUT http://localhost:9200/test/_settings -d &#39;{&quot;index&quot;:{&quot;number_of_replicas&quot;:0}}&#39;</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vps.net - You get what you pay for]]></title>
    <link href="http://ruflin.com/2011/10/29/vps-dot-net-you-get-what-you-pay-for/"/>
    <updated>2011-10-29T14:21:00+02:00</updated>
    <id>http://ruflin.com/2011/10/29/vps-dot-net-you-get-what-you-pay-for</id>
    <content type="html"><![CDATA[<p>I have been a <a href="http://vps.net/">vps.net</a> user for more than two years. A few days ago vps.net <a href="http://www.vps.net/blog/2011/10/27/were-going-to-one-up-ourselves-and-give-you-a-free-node/">published a blog post</a> on offering a free node for every user that writes a blog post on their service. So here we are.</p></p>

<p>The most important message first: With vps.net, you get what you pay for. This can be seen in a positive, but also a negative way. Vps.net is one of the cheaper VPS hosts (as long as you don’t use lots of nodes), but at the same time it is one of the less stable ones. The performance is good, but they have quite some downtime. So if you are looking for a cheap server with good speed, vps.net is not such a bad choice, but if you plan on running a production server or other things that should be up 24/7, I would recommend looking somewhere else (where you will pay more).</p>




<p><p>An alternative to vps.net that I have been wanting to try out for a long time now, is <a href="http://www.linode.com/">Linode</a>. In contrast to vps.net they increased the amount of RAM you get for a single node in the last two years. The 376MB on vps.net are really not that much.</p>

<p><p>For everyone who wants to hear more details, I had the following story with vps.net in the last two years.</p></p>

<p><h2>Scaling &ndash; Up (sometimes) but not down</h2></p>

<p><p>About two years ago we started to host <a href="http://useKit.com/">useKit.com</a> on vps.net, as we wanted it to scale as soon as we had more traffic on the site. But there were several issues with what we had in mind. Scaling up was easy (most of the time), but scaling down took forever and every time we wanted to scale down, we had to shut down our servers (I don’t know if that is better now) for quite a long time, which was not really a favourable to our business. Also, we were so unlucky that vps.net had some downtime every time we had the most traffic on our servers, which was quite bad for our users (and for us).</p></p>

<p><p>Sometimes, when we had peak traffic on our servers, one server just stopped working from one second to the other. In the log it looked like someone pulled the plug from the server. During more than 3 months, I discussed this problem forth and back with the vps.net support. Until the end it was unclear what the real problem was, but vps.net always suggested it is probably related to the setup, even though it runs on others servers without any issues. Because of this (and other things mentioned above) we decided to move all our production servers to another host, were all these problems did not appear again.</p></p>

<p><p>As we are using quite a few so called <a href="http://www.scribd.com/doc/49968664/Storing-and-Analyzing-Social-Data">NoSQL database systems</a> like <a href="http://www.mongodb.org/">MongoDB</a>, <a href="http://redis.io/">Redis</a> and <a href="http://www.elasticsearch.org/">elasticsearch</a>, we need servers that can handle quite a high number of open files. In general this is not a problem when Linux is configured correctly. But as the issue above always happened when one of these servers had a small peak, I assumed it was related to this issue.</p></p>

<p><h2>Support &ndash; Solving issues but not resolving problems</h2></p>

<p><p>Because of the issues we had, I had a lot of contact with the vps.net support. First the good thing: They reply quite fast and can fix the issue most of the time. The bad thing is, if you have a real problem, the support can be quite frustrating. If you open a ticket that goes forth and back you will have contact to several different supporters. Sometimes after having discussed a subject forth and back, the supporter changed and the whole thing started from the beginning. The same questions were asked again. I somehow got the feeling that sometimes they were too lazy to read up what was discussed before.</p></p>

<p><p>But the main problem for me was that they were good at fixing issues, but they were not good at all at explaining how the issue was resolved or what the issue was. That was something I always asked but never got a good answer. If I want to run my production servers on a host, I want to know in more detail what kinds of issues he has and how he resolves the issue. I want to know whether my issue was something unexpected that happened and is fixed now and should not happen again or whether it is an open bug.</p></p>

<p><p>One thing that describes this quite good is an issue that I had about ten times in the last two years: My server stats in the vps.net admin panel disappeared. Sometimes they just stopped working even though my server was still running and my own stats (<a href="http://www.cacti.net/">Cacti</a>) showed the right results. Every time I contacted the vps.net support, the issue was fixed in a few minutes, but they never explained to me why this happened again and again. I felt like they were just restarting the stats service every time they got this bug report but never tried to figure out why it happened.</p></p>

<p><p>There are a few really good support engineers at vps.net, mostly L3 (or higher?). But it is soooo hard to get trough to them. The best answer I got from a L1 supporter for the problem above (as no stats were shown) was that this is not an issue as my server has 0 traffic and 0 cpu usage and this is the reason that nothing is shown (really?).</p></p>

<p><p>A small side story just happened a week ago. Vps.net planned on moving my node to a new cluster. They sent me an e-mail three days before they planned to move my node and informed me that my server will be down for 2-3h. If it were a production server, this would not be acceptable for me. This is a too short notice and the time was during the most traffic on the server. Imagine all your nodes were be on the same cluster &hellip; Even worse, I had some downtime, but they failed to move the server and scheduled it again for next week? Apparently they had some issues but never mentioned what the issues were &hellip;</p></p>

<p><p>At the moment, I still have a small development server at vps.net to run continuous integration tests for some open source projects such as <a href="https://github.com/ruflin/Elastica">Elastica</a>. But all my other servers that have to be up 24/7 I moved to other hosters. What is nice about vps.net is that it is really simple to just start up a single additional node for one day to make some tests for only $1.</p></p>

<p><h2>Conclusion</h2></p>

<p><p>Vps.net is nice for some cheap test nodes, but not for production servers.</p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Storing and Analyzing Social Data]]></title>
    <link href="http://ruflin.com/2011/04/17/storing-and-analyzing-social-data/"/>
    <updated>2011-04-17T14:24:00+02:00</updated>
    <id>http://ruflin.com/2011/04/17/storing-and-analyzing-social-data</id>
    <content type="html"><![CDATA[<p>From July 2010 to December 2010 I worked on my master thesis &#8220;Storing and Analyzing Social Data&#8221;. It is about the structure of social data, how to store social data (i.e. NoSQL solutions) and the processing of social data. You can download the full thesis <a href="http://ruflin.com/files/Storing-and-Analyzing-Social-Data.pdf">here</a>.</p>




<p>For a short overview, here is the abstract of the thesis and the embedded pdf.</p>




<h2>Abstract</h2>




<p><i>Social platforms such as Facebook and Twitter have been growing exponentially in the last few years. As a result of this growth, the amount of social data increased enormously. The need for storing and analyzing social data became crucial. New storage solutions – also called NoSQL – were therefore created to fulfill this need. This thesis will analyze the structure of social data and give an overview of cur- rently used storage systems and their respective advantages and disadvantages for differently structured social data. Thus, the main goal of this thesis is to find out the structure of social data and to identify which types of storage systems are suit- able for storing and processing social data. Based on concrete implementations of the different storage systems it is analyzed which solutions fit which type of data and how the data can be processed and analyzed in the respective system. A focus lies on simple analyzing methods such as the degree centrality and simplified PageRank calculations.</i></p>




<h2>Master Thesis</h2>


<p><a title="View Storing and Analyzing Social Data on Scribd" href="http://www.scribd.com/doc/49968664/Storing-and-Analyzing-Social-Data" style="margin: 12px auto 6px auto; font-family: Helvetica,Arial,Sans-serif; font-style: normal; font-variant: normal; font-weight: normal; font-size: 14px; line-height: normal; font-size-adjust: none; font-stretch: normal; -x-system-font: none; display: block; text-decoration: underline;">Storing and Analyzing Social Data</a><iframe class="scribd_iframe_embed" src="http://www.scribd.com/embeds/49968664/content?start_page=1&view_mode=list&access_key=key-2gkqadzlowsgr3j7fla1" data-auto-height="true" data-aspect-ratio="0.707514450867052" scrolling="no" id="doc_57313" width="100%" height="600" frameborder="0"></iframe><script type="text/javascript">(function() { var scribd = document.createElement(&ldquo;script&rdquo;); scribd.type = &ldquo;text/javascript&rdquo;; scribd.async = true; scribd.src = &ldquo;<a href="http://www.scribd.com/javascripts/embed_code/inject.js">http://www.scribd.com/javascripts/embed_code/inject.js</a>&rdquo;; var s = document.getElementsByTagName(&ldquo;script&rdquo;)[0]; s.parentNode.insertBefore(scribd, s); })();</script></p>
]]></content>
  </entry>
  
</feed>
