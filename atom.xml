<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Ruflin]]></title>
  <link href="http://ruflin.com/atom.xml" rel="self"/>
  <link href="http://ruflin.com/"/>
  <updated>2014-06-11T20:46:47+02:00</updated>
  <id>http://ruflin.com/</id>
  <author>
    <name><![CDATA[@ruflin]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Quality in software projects matters from day one]]></title>
    <link href="http://ruflin.com/2014/06/10/quality-in-software-projects-matters-from-day-one/"/>
    <updated>2014-06-10T20:43:14+02:00</updated>
    <id>http://ruflin.com/2014/06/10/quality-in-software-projects-matters-from-day-one</id>
    <content type="html"><![CDATA[<p>As I see <a href="http://en.wikipedia.org/wiki/Software_quality">quality in software</a> as one of the most important features when building software, I will dedicate my next blog posts on software quality and quality standards. For most non-engineers, quality in software projects is something very abstract. I will therefore now and then make comparisons to building a car, since most people are more famliar with cars and objects they can actually touch and feel. My first post will be about why it matters to get quality into your software project from day one.</p>

<p>Quality in software projects is a topic that lots of engineers talk about and also embrace. I rarely witness discussions where engineers argue against the importance of quality. The only situation where the question of quality might be an issue is when talking about building a prototype or writing the first lines of code of a project. Should you have quality standards in your prototype? Should you start your project already with tests?</p>

<p>My answer to this is: If you plan to run your software multiple times, you should. If you build a prototype for example during a hackathon that only needs to run once, perhaps you can build it without including some basic tests. But even in this situation, I belive that having some basic quality measures in your code will prevent nasty surprises during your presentation.</p>

<p>The beautiful thing about software is that it normally not only runs once, but can be executed thousands or millions of times without additional costs (except sever costs). If you build software that is only executed once, why would you even build it? That is why quality standards also matter in your prototype. Your prototype will be executed lots of times and will go through various iterations. A prototype will have lower quality standards than a production system. To draw the comparison to building a car here: The first time you build a new car, you will not test 100 times if the blinker works as expected, but you will make sure that the breaks actually work. The same for your prototype, make sure you have at least tested the core functionality.</p>

<p>More than once I have witnessed a prototype actually making it into production, the so-called <a href="http://blog.codinghorror.com/new-programming-jargon/">Proto-duction</a>. No, this should not happen, but if you start shipping your prototype and actual real users start to use it, it is very hard to convince the users and your business unit that you have to start from scratch again because you didn&rsquo;t plan this software to actually be for users. If we make the comparison with the car again, we shippped it to the user and made sure the accelarator actually works as expected, as this is the first things users test, but we didn&rsquo;t put much thought into how the breaks are applied if the car actually is going down and not on a flat street. Depending on how bad your &ldquo;break&rdquo; issue in your sofware is, perhaps it makes sense to take it away from your users again and build it from scratch.</p>

<p>To prevent Proto-Duction issues, get quality in your software projects from day one and make sure your quality is easily measured. More on how to make measuring your quality easy in the next post.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting started with the Internet of Things]]></title>
    <link href="http://ruflin.com/2013/06/08/getting-started-with-the-internet-of-things/"/>
    <updated>2013-06-08T23:53:00+02:00</updated>
    <id>http://ruflin.com/2013/06/08/getting-started-with-the-internet-of-things</id>
    <content type="html"><![CDATA[<p>The term <a href="http://en.wikipedia.org/wiki/Internet_of_Things">Internet of Things</a> has been around for quite some time. Until recently, however, the things were mostly offline and could only connect to the internet through a mobile phone, for example via scanning a QR code. This changed in the last months and years with quite a few start-ups that entered the market, such as <a href="http://ninjablocks.com/">Ninja Blocks</a> or <a href="http://www.smartthings.com/">SmartThings</a> and devices such as <a href="http://hitekelec.com/myknut/">Knut</a> or <a href="http://supermechanical.com/">Twine</a>, as well as larger companies such as Philips with the <a href="http://www.meethue.com/">Hue Lightbulb</a>. Some of them are based on standards such as <a href="http://www.zigbee.org/">Zigbee</a> or have their own implementation.</p>

<p>The introduction of very cheap and simple computers such as the <a href="http://www.raspberrypi.org/">Raspberry PI</a> and <a href="http://www.arduino.cc/">Arduino</a> had a huge impact on the internet of things. The sensors that had until then been mostly offline  can suddenly be connected to a cheap computer which connects to the internet. This makes it possible to access the sensors at any time from any location, mainly from the smart phone. It is even possible to interact with the sensor, for example turning the light on or opening a door.</p>

<p>Most of these sensors can only do one thing and are basically &ldquo;stupid&rdquo;. But the power is and will be added through software. As these sensors are now all connected to each other, it is possible to write applications that interact with the sensors and make the whole system intelligent.</p>

<p>From my point of view, the Internet of Things just got started. The more the things disappear and the more intelligent the interaction is, the more it will help us in our daily lives, and we will completely forget how it was possible to live without it. It will take a few years until these kind of things will be built into houses, but I think we are now at a good point to finally get the Internet of Things running.</p>

<p>After playing around with a Raspberry PI for quite some time, I finally ordered a <a href="http://ninjablocks.com/products/ninja-blocks-kit">Ninja Blocks Kit</a>. I decided to go with the Ninja Blocks Kit for different reasons. First, I was only looking for a humidity sensor which I could monitor remotely. This is offered by various providers. What I like about the Ninja Blocks is that it is all based on Open Source. Not only the software is open source, but also the hardware plans are on Github. The product is at the moment probably more focused on Geeks than normal end users, but that&rsquo;s how the whole thing starts. I would predict that in the next months there will be lots of small startups which build up on this basic infrastructure/service to provide end user friendly solutions for all kinds of stuff such as home monitoring, gardening and lots more.</p>

<p>I really look forward to getting my Ninja Blocks Kit. As soon as I get it I will post an update/review.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[From Joomla to Octopress]]></title>
    <link href="http://ruflin.com/2013/05/19/from-joomla-to-octopress/"/>
    <updated>2013-05-19T00:00:00+02:00</updated>
    <id>http://ruflin.com/2013/05/19/from-joomla-to-octopress</id>
    <content type="html"><![CDATA[<p>After more than a year, I finally managed to upgrade my private website / blog. My blog and gallery used to be based on Joomla, as I was a contributor to Joomla some years ago and had built some extensions which were running my site. Every time Joomla released a large update I ran into trouble because either I was too lazy to upgrade my extensions or another external extension didn&rsquo;t work properly with the upgrade. Naturally, it always took me forever to upgrade my website (even for security updates) and when I did upgrade, some stuff was broken.</p>

<p>Finally more than a year ago, I decided to switch to something simpler, perhaps even something that I didn&rsquo;t have to host myself. I tried different services like Tubmlr, Posterous, Wordpress and more. These are all great solutions and make your life easier when you only want to blog. What bugs me with all these solutions is that it&rsquo;s again very hard to move to a different service in case one of these services stops working &mdash;  like Posteurous recently.</p>

<p>I prefer to write my blog post not in a WYSIWYG editor even if it supports raw text. From time to time, I want to insert some JavaScript or other things that the editors manage to break. So I was looking for a solution where I can write blog posts in a standardized format (HTML, Markdown) if possible in my preferred editor. Because of Github pages I stumbled over <a href="https://github.com/mojombo/jekyll">Jekyll</a>. At first, I was very sceptical as I thought it is too limiting. On my old blog, I had some fancy extensions such as gallery and other stuff.</p>

<p>From Jekyll I moved to <a href="http://octopress.org/">Octopress</a>, as it offers some nice additions to Jekyll. What I really like about the solution is that it allows me to define my urls, have pages and posts and makes it really easy to deploy. The first plan was to migrate all blog entries from the old blog to the new one. As these were in two different languages and I couldn&rsquo;t find an import script for Joomla, I decided to only migrate some blog entries related to Elastica and start from scratch.</p>

<p>So here is the new clean blog which will hopefully be filled with content again soon. At the moment I&rsquo;m really happy with the new solution. Is is very easy to create blog entries and putting content online is just one command.</p>

<p>In case you miss some old blog entries you would like to have them online again, please let me now by sending a tweet to <a href="https://twitter.com/ruflin">@ruflin</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Include Elastica in your project as svn:externals]]></title>
    <link href="http://ruflin.com/2011/12/21/include-elastica-in-your-project-as-svn-externals/"/>
    <updated>2011-12-21T10:57:00+01:00</updated>
    <id>http://ruflin.com/2011/12/21/include-elastica-in-your-project-as-svn-externals</id>
    <content type="html"><![CDATA[<p>As most of you know, <a href="https://github.com/ruflin/Elastica">Elastica</a> is hosted on <a href="https://github.com/">github</a>, which means it uses <a href="http://git-scm.com/">git</a> as its <a href="http://en.wikipedia.org/wiki/Version_control">revision control</a> system. I have several projects which include Elastica but use <a href="http://subversion.tigris.org/">subversion</a> as its version control system. Until now, I included Elastica as an external svn source by hosting my own Elastica svn repository. But yesterday I discovered that the code from github can also be checked out through svn. I immediately asked google to get more details about this feature and discovered several blog entries on the <a href="https://github.com/blog/966-improved-subversion-client-support">github blog</a> which I had somehow missed.</p>




<p>It is not only possible to check out repositories, but also to check out some specific subfolders or tags and you can even commit to the repository (which I didn&#8217;t test). As in my projects I only use the Elastica library folder and don&#8217;t need all the tests and additional data, I check out only the lib folder. If you want to check out the Elastica lib folder from version v0.18.6.0, use the following line of code:</p>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>svn co https://github.com/ruflin/Elastica/tags/v0.18.6.0/lib/ .</span></code></pre></td></tr></table></div></figure>




<p>If you have a lib folder in your project with all your frameworks and libraries and you want to add Elastica as an external source (which is quite useful), you can set the <a href="http://svnbook.red-bean.com/en/1.0/ch07s03.html">svn:externals property</a> on your library folder to the following.</p>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>https://github.com/ruflin/Elastica/tags/v0.18.6.0/lib/Elastica Elastica</span></code></pre></td></tr></table></div></figure>




<p>If you already have other sources added as externals to your repository (for example ZF), just add this line below your existing lines. The next time you will update your repository, the Elastica folder with all its files will be checked out. To update to one of the next versions of Elastica, update the version number in the url in your svn:externals properties.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Elastica with multiple Elasticsearch Nodes]]></title>
    <link href="http://ruflin.com/2011/11/21/using-elastica-with-multiple-elasticsearch-nodes/"/>
    <updated>2011-11-21T13:05:00+01:00</updated>
    <id>http://ruflin.com/2011/11/21/using-elastica-with-multiple-elasticsearch-nodes</id>
    <content type="html"><![CDATA[<p>Elasticsearch was built with the cloud / multiple distributed servers in mind. It is quite easy to start a <a href="http://www.elasticsearch.org/guide/reference/modules/cluster.html">elasticsearch cluster</a> simply by starting multiple instances of elasticsearch on one server or on multiple servers. Every elasticsearch instance is called <a href="http://www.elasticsearch.org/guide/reference/api/admin-cluster-nodes-info.html">a node</a>. To start multiple instances of elasticsearch on your local machine, just run the following command in the elasticsearch folder twice:</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>./bin/elasticsearch -f
</span><span class='line'>./bin/elasticsearch -f
</span></code></pre></td></tr></table></div></figure>




<p>As you will see, the first node will be started on port 9200, the second instance on port 9201. Elasticsearch automatically discovers the other node and creates a cluster. Elastica can be used to retrieve all node and cluster information. In the following example first the cluster object is retrieved (Elastica_Cluster) from the client and then the <a href="http://www.elasticsearch.org/guide/reference/api/admin-cluster-state.html">cluster state</a> is read out. Then all cluster nodes (Elastica_Node) are retrieved and the name of every node is printed out. Every cluster has at least one node and every node has a specific name.</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="nv">$client</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Elastica_Client</span><span class="p">();</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Retrieve a Elastica_Cluster object</span>
</span><span class='line'><span class="nv">$cluster</span> <span class="o">=</span> <span class="nv">$client</span><span class="o">-&gt;</span><span class="na">getCluster</span><span class="p">();</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Returns the cluster state</span>
</span><span class='line'><span class="nv">$state</span> <span class="o">=</span> <span class="nv">$cluster</span><span class="o">-&gt;</span><span class="na">getState</span><span class="p">();</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Gets all cluster notes</span>
</span><span class='line'><span class="nv">$nodes</span> <span class="o">=</span> <span class="nv">$cluster</span><span class="o">-&gt;</span><span class="na">getNodes</span><span class="p">();</span>
</span><span class='line'>
</span><span class='line'><span class="k">foreach</span> <span class="p">(</span><span class="nv">$nodes</span> <span class="k">as</span> <span class="nv">$node</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">echo</span> <span class="nv">$node</span><span class="o">-&gt;</span><span class="na">getName</span><span class="p">();</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>




<h2>Client to multiple servers</h2>




<p>As elasticsearch is a distributed search engine that can be run on multiple servers, it is possible that some servers fail and still, the search works as expected as the data is stored redundantly (replicas). The <a href="http://www.elasticsearch.org/guide/reference/api/admin-indices-create-index.html">number of shards and replicas</a> can be chosen for every single index during creation. Of course, this can also be set with Elastica through the mapping as can be seen in the <a href="https://github.com/ruflin/Elastica/blob/master/test/lib/Elastica/IndexTest.php">Elastica_Index test</a>. More details on this perhaps in a later blog post.</p>




<p>One of the goals of the distributed search index is availability. If one server goes down, search results should still be served. But if the client connects to only the server that just went down, no results are returned anymore. Because of this, Elastica_Client supports multiple servers which are accessed in a round robin algorithm. This is the only and also most basic option at the moment. So if we start a node on port 9200 and port 9201 above, we pass the following arguments to Elastica_Client to access both servers.</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="nv">$client</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Elastica_Client</span><span class="p">(</span><span class="k">array</span><span class="p">(</span>
</span><span class='line'>  <span class="s1">&#39;servers&#39;</span> <span class="o">=&gt;</span> <span class="k">array</span><span class="p">(</span>
</span><span class='line'>      <span class="k">array</span><span class="p">(</span><span class="s1">&#39;host&#39;</span> <span class="o">=&gt;</span> <span class="s1">&#39;localhost&#39;</span><span class="p">,</span> <span class="s1">&#39;port&#39;</span> <span class="o">=&gt;</span> <span class="mi">9200</span><span class="p">)</span>
</span><span class='line'>      <span class="k">array</span><span class="p">(</span><span class="s1">&#39;host&#39;</span> <span class="o">=&gt;</span> <span class="s1">&#39;localhost&#39;</span><span class="p">,</span> <span class="s1">&#39;port&#39;</span> <span class="o">=&gt;</span> <span class="mi">9201</span><span class="p">)</span>
</span><span class='line'>  <span class="p">)</span>
</span><span class='line'><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure>




<p>From now on, every request is sent to one of these servers in a round robin type. Instead of localhost, an external server could be used in addition. I&#8217;m aware that this is still a quite basic implementation. As probably some of you already realized, this is no safe failover method, as every second request still goes onto the server that is down. One idea here is to give a specific threshold for every server in which the respond time should be and otherwise the query goes to the next server. In addition, it would be useful to store this information on unavailable servers somewhere in order to use it for the next request. Thus, only one client has to wait for the unavailable server. Storing this information is somehow an issue, since Elastica does not have any storage backend.</p>




<h2>Load Distribution</h2>




<p>This client implementation also allows to distribute the load on multiple nodes. As far as I know, Elasticsearch already does this quite well on its own. But it helps if more than one node can answer http requests. Therefore, the method above is really useful if you use more than one elasticsearch node in a cluster to send your request to all servers.</p>




<p>It is planned to enhance this multiple server implementation in the future with additional parameters such as priority for a server and some other ideas. Please feel free to write down your ideas in the comment section or directly create a pull request on github.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Log Requests in Elastica]]></title>
    <link href="http://ruflin.com/2011/11/20/how-to-log-requests-in-elastica/"/>
    <updated>2011-11-20T13:46:00+01:00</updated>
    <id>http://ruflin.com/2011/11/20/how-to-log-requests-in-elastica</id>
    <content type="html"><![CDATA[<p>In the <a href="https://github.com/ruflin/Elastica/tree/v0.18.4.1" target="_blank">Elastica Release v0.18.4.1</a>, the capability to log requests was added. There is a general Elastica_Log object that can later also be extended to log other things such as responses, exceptions and more. The Elastica_Log constructor takes an Elastica_Client as param. To enable logging, the config variable log for the client has to be set to true, or a specific path the log should be written to. This means that every client instance decides on its own whether logging is enabled or not.</p>




<p>The example below will log the message &#8220;hello world&#8221; to the general PHP log.</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="nv">$client</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Elastica_Client</span><span class="p">(</span><span class="k">array</span><span class="p">(</span><span class="s1">&#39;log&#39;</span> <span class="o">=&gt;</span> <span class="k">true</span><span class="p">));</span>
</span><span class='line'><span class="nv">$log</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Elastica_Log</span><span class="p">(</span><span class="nv">$client</span><span class="p">);</span>
</span><span class='line'><span class="nv">$log</span><span class="o">-&gt;</span><span class="na">log</span><span class="p">(</span><span class="s1">&#39;hello world&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>




<br />




<p>If a file path is set as the log config param, the error log will write the &#8220;hello world&#8221; message to the /tmp/php.log file.</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="nv">$client</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Elastica_Client</span><span class="p">(</span><span class="k">array</span><span class="p">(</span><span class="s1">&#39;log&#39;</span> <span class="o">=&gt;</span> <span class="s1">&#39;/tmp/php.log&#39;</span><span class="p">));</span>
</span><span class='line'><span class="nv">$log</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Elastica_Log</span><span class="p">(</span><span class="nv">$client</span><span class="p">);</span>
</span><span class='line'><span class="nv">$log</span><span class="o">-&gt;</span><span class="na">log</span><span class="p">(</span><span class="s1">&#39;hello world&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>




<br />




<p>If logging is enabled, all request are at the moment automatically logged. There is a special conversion of request to log messages. The log message is converted to the shell format, so every log line can directly be pasted into the shell to test out. This is quite nice to debug and to create a gist if others ask what the query looks like. Furthermore, this makes it simpler to figure out whether the problem relates to Elastica or not.</p>




<p>For example the output for updating the number of replicas setting request for the index test would look like below.</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">curl -XPUT http://localhost:9200/test/_settings -d &#39;{&quot;index&quot;:{&quot;number_of_replicas&quot;:0}}&#39;</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Storing and Analyzing Social Data]]></title>
    <link href="http://ruflin.com/2011/04/17/storing-and-analyzing-social-data/"/>
    <updated>2011-04-17T14:24:00+02:00</updated>
    <id>http://ruflin.com/2011/04/17/storing-and-analyzing-social-data</id>
    <content type="html"><![CDATA[<p>From July 2010 to December 2010 I worked on my master thesis &#8220;Storing and Analyzing Social Data&#8221;. It is about the structure of social data, how to store social data (i.e. NoSQL solutions) and the processing of social data. You can download the full thesis <a href="http://ruflin.com/files/Storing-and-Analyzing-Social-Data.pdf">here</a>.</p>




<p>For a short overview, here is the abstract of the thesis and the embedded pdf.</p>




<h2>Abstract</h2>




<p><i>Social platforms such as Facebook and Twitter have been growing exponentially in the last few years. As a result of this growth, the amount of social data increased enormously. The need for storing and analyzing social data became crucial. New storage solutions – also called NoSQL – were therefore created to fulfill this need. This thesis will analyze the structure of social data and give an overview of cur- rently used storage systems and their respective advantages and disadvantages for differently structured social data. Thus, the main goal of this thesis is to find out the structure of social data and to identify which types of storage systems are suit- able for storing and processing social data. Based on concrete implementations of the different storage systems it is analyzed which solutions fit which type of data and how the data can be processed and analyzed in the respective system. A focus lies on simple analyzing methods such as the degree centrality and simplified PageRank calculations.</i></p>




<h2>Master Thesis</h2>


<p><a title="View Storing and Analyzing Social Data on Scribd" href="http://www.scribd.com/doc/49968664/Storing-and-Analyzing-Social-Data" style="margin: 12px auto 6px auto; font-family: Helvetica,Arial,Sans-serif; font-style: normal; font-variant: normal; font-weight: normal; font-size: 14px; line-height: normal; font-size-adjust: none; font-stretch: normal; -x-system-font: none; display: block; text-decoration: underline;">Storing and Analyzing Social Data</a><iframe class="scribd_iframe_embed" src="http://www.scribd.com/embeds/49968664/content?start_page=1&view_mode=list&access_key=key-2gkqadzlowsgr3j7fla1" data-auto-height="true" data-aspect-ratio="0.707514450867052" scrolling="no" id="doc_57313" width="100%" height="600" frameborder="0"></iframe><script type="text/javascript">(function() { var scribd = document.createElement(&ldquo;script&rdquo;); scribd.type = &ldquo;text/javascript&rdquo;; scribd.async = true; scribd.src = &ldquo;<a href="http://www.scribd.com/javascripts/embed_code/inject.js">http://www.scribd.com/javascripts/embed_code/inject.js</a>&rdquo;; var s = document.getElementsByTagName(&ldquo;script&rdquo;)[0]; s.parentNode.insertBefore(scribd, s); })();</script></p>
]]></content>
  </entry>
  
</feed>
